{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the training data\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# Apply one-hot encoding to categorical columns\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Apply the same one-hot encoding to test data\n",
    "df_test = pd.get_dummies(df_test)\n",
    "\n",
    "# Drop columns as needed\n",
    "text_to_find = 'noninvasive'\n",
    "columns_to_drop = [col for col in df.columns if text_to_find in col]\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "df_test.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "numeric_columns = df.select_dtypes(include=['int64','float64']).columns\n",
    "numeric_columns = numeric_columns.drop(['RecordID', 'hospital_id', 'icu_id', 'hospital_death'])\n",
    "object_columns = df.select_dtypes(include=['object']).columns\n",
    "object_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/irtiza/Documents/IML assignment 1/iml-fall-2023-first-challenge/lgbm_best4.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/irtiza/Documents/IML%20assignment%201/iml-fall-2023-first-challenge/lgbm_best4.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m imr \u001b[39m=\u001b[39m KNNImputer(n_neighbors\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m, weights\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/irtiza/Documents/IML%20assignment%201/iml-fall-2023-first-challenge/lgbm_best4.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m imr \u001b[39m=\u001b[39m imr\u001b[39m.\u001b[39mfit(df\u001b[39m.\u001b[39mvalues)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/irtiza/Documents/IML%20assignment%201/iml-fall-2023-first-challenge/lgbm_best4.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df[:] \u001b[39m=\u001b[39m imr\u001b[39m.\u001b[39;49mtransform(df\u001b[39m.\u001b[39;49mvalues)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/irtiza/Documents/IML%20assignment%201/iml-fall-2023-first-challenge/lgbm_best4.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m imr_test \u001b[39m=\u001b[39m KNNImputer(n_neighbors\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m, weights\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/irtiza/Documents/IML%20assignment%201/iml-fall-2023-first-challenge/lgbm_best4.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m imr_test \u001b[39m=\u001b[39m imr_test\u001b[39m.\u001b[39mfit(df_test\u001b[39m.\u001b[39mvalues)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/impute/_knn.py:365\u001b[0m, in \u001b[0;36mKNNImputer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[39m# process in fixed-memory chunks\u001b[39;00m\n\u001b[1;32m    357\u001b[0m gen \u001b[39m=\u001b[39m pairwise_distances_chunked(\n\u001b[1;32m    358\u001b[0m     X[row_missing_idx, :],\n\u001b[1;32m    359\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m     reduce_func\u001b[39m=\u001b[39mprocess_chunk,\n\u001b[1;32m    364\u001b[0m )\n\u001b[0;32m--> 365\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m gen:\n\u001b[1;32m    366\u001b[0m     \u001b[39m# process_chunk modifies X in place. No return value.\u001b[39;00m\n\u001b[1;32m    367\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_empty_features:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/pairwise.py:2018\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   2016\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2017\u001b[0m     X_chunk \u001b[39m=\u001b[39m X[sl]\n\u001b[0;32m-> 2018\u001b[0m D_chunk \u001b[39m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[39m=\u001b[39;49mmetric, n_jobs\u001b[39m=\u001b[39;49mn_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   2019\u001b[0m \u001b[39mif\u001b[39;00m (X \u001b[39mis\u001b[39;00m Y \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[39m.\u001b[39mget(\n\u001b[1;32m   2020\u001b[0m     metric, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2021\u001b[0m ) \u001b[39mis\u001b[39;00m euclidean_distances:\n\u001b[1;32m   2022\u001b[0m     \u001b[39m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[1;32m   2023\u001b[0m     \u001b[39m# i.e. \"l2\"\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m     D_chunk\u001b[39m.\u001b[39mflat[sl\u001b[39m.\u001b[39mstart :: _num_samples(X) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/pairwise.py:2196\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2193\u001b[0m         \u001b[39mreturn\u001b[39;00m distance\u001b[39m.\u001b[39msquareform(distance\u001b[39m.\u001b[39mpdist(X, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[1;32m   2194\u001b[0m     func \u001b[39m=\u001b[39m partial(distance\u001b[39m.\u001b[39mcdist, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m-> 2196\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/pairwise.py:1766\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1763\u001b[0m X, Y, dtype \u001b[39m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1765\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1766\u001b[0m     \u001b[39mreturn\u001b[39;00m func(X, Y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   1768\u001b[0m \u001b[39m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1769\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/pairwise.py:494\u001b[0m, in \u001b[0;36mnan_euclidean_distances\u001b[0;34m(X, Y, squared, missing_values, copy)\u001b[0m\n\u001b[1;32m    491\u001b[0m X[missing_X] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    492\u001b[0m Y[missing_Y] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 494\u001b[0m distances \u001b[39m=\u001b[39m euclidean_distances(X, Y, squared\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    496\u001b[0m \u001b[39m# Adjust distances for missing values\u001b[39;00m\n\u001b[1;32m    497\u001b[0m XX \u001b[39m=\u001b[39m X \u001b[39m*\u001b[39m X\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/pairwise.py:338\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[39mif\u001b[39;00m Y_norm_squared\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m (\u001b[39m1\u001b[39m, Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[1;32m    333\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    334\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIncompatible dimensions for Y of shape \u001b[39m\u001b[39m{\u001b[39;00mY\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    335\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mY_norm_squared of shape \u001b[39m\u001b[39m{\u001b[39;00moriginal_shape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    336\u001b[0m         )\n\u001b[0;32m--> 338\u001b[0m \u001b[39mreturn\u001b[39;00m _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/pairwise.py:379\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    376\u001b[0m     distances \u001b[39m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[1;32m    377\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     \u001b[39m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m     distances \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m safe_sparse_dot(X, Y\u001b[39m.\u001b[39;49mT, dense_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    380\u001b[0m     distances \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m XX\n\u001b[1;32m    381\u001b[0m     distances \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m YY\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:192\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    190\u001b[0m         ret \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(a, b)\n\u001b[1;32m    191\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     ret \u001b[39m=\u001b[39m a \u001b[39m@\u001b[39;49m b\n\u001b[1;32m    194\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    195\u001b[0m     sparse\u001b[39m.\u001b[39missparse(a)\n\u001b[1;32m    196\u001b[0m     \u001b[39mand\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(b)\n\u001b[1;32m    197\u001b[0m     \u001b[39mand\u001b[39;00m dense_output\n\u001b[1;32m    198\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ret, \u001b[39m\"\u001b[39m\u001b[39mtoarray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    199\u001b[0m ):\n\u001b[1;32m    200\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39mtoarray()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# imr = KNNImputer(n_neighbors=10000, weights='uniform')\n",
    "# imr = imr.fit(df.values)\n",
    "# df[:] = imr.transform(df.values)\n",
    "\n",
    "# imr_test = KNNImputer(n_neighbors=10000, weights='uniform')\n",
    "# imr_test = imr_test.fit(df_test.values)\n",
    "# df_test[:] = imr_test.transform(df_test.values)\n",
    "imr = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "df[numeric_columns] = imr.fit_transform(df[numeric_columns].values)\n",
    "\n",
    "rbs1 = RobustScaler()\n",
    "df[numeric_columns] = rbs1.fit_transform(df[numeric_columns])\n",
    "\n",
    "imr_test = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "df_test[numeric_columns] = imr_test.fit_transform(df_test[numeric_columns].values)\n",
    "\n",
    "rbs = RobustScaler()\n",
    "df_test[numeric_columns] = rbs.fit_transform(df_test[numeric_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='hospital_death')\n",
    "y = df['hospital_death']\n",
    "\n",
    "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Check if 'hospital_death' is in numeric_columns before dropping it\n",
    "if 'hospital_death' in numeric_columns:\n",
    "    numeric_columns = numeric_columns.drop(['RecordID', 'hospital_id', 'icu_id', 'hospital_death'])\n",
    "else:\n",
    "    # Handle the case where 'hospital_death' is not in numeric_columns\n",
    "    print(\"Warning: 'hospital_death' not found in numeric_columns\")\n",
    "\n",
    "rbs = RobustScaler()\n",
    "X[numeric_columns] = rbs.fit_transform(X[numeric_columns])\n",
    "df_test[numeric_columns] = rbs.transform(df_test[numeric_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the LightGBM parameters\n",
    "lgbm_params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'colsample_bytree': 0.8,\n",
    "    'subsample': 0.8,\n",
    "    'reg_alpha': 0.9,\n",
    "    'reg_lambda': 0.8,\n",
    "    'n_jobs': -1,\n",
    "    'num_leaves': 10\n",
    "}\n",
    "\n",
    "# Create a LightGBMClassifier as the base estimator\n",
    "base_lgbm_model = LGBMClassifier(n_estimators=500, random_state=42, **lgbm_params)\n",
    "\n",
    "# Create a BaggingClassifier with LightGBM as the base estimator\n",
    "bagging_lgbm_model = BaggingClassifier(base_estimator=base_lgbm_model, n_estimators=200, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for the grid search\n",
    "param_grid = {\n",
    "    'base_estimator__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'base_estimator__max_depth': [3, 4, 5],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(estimator=bagging_lgbm_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search on the training data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best hyperparameters and corresponding accuracy score\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy Score:\", grid_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
